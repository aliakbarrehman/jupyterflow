{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"JupyterFlow Documentation \u00b6 Run your workflow on JupyterHub! What is JupyterFlow? \u00b6 Run Argo Workflow pipeline on JupyterHub. No Kubernetes knowledge (YAML) needed to run. No container build & push or deploy. Just simply run your workflow with single command jupyterflow . jupyterflow is a command that helps user utilize Argo Workflow engine without making any YAML files or building containers on JupyterHub. The following jupyterflow command will make sequence workflow. jupyterflow run -c \"python hello.py >> python world.py\" Getting Started \u00b6 To set up jupyterflow and start running your first workflow, follow the Getting Started guide. How does it work \u00b6 To learn how it works, see How it works guide. Examples \u00b6 For examples how to use, please see Examples page. workflow.yaml Configuration \u00b6 To find out more detail configuration, look at Configuration page.","title":"Overview"},{"location":"#jupyterflow-documentation","text":"Run your workflow on JupyterHub!","title":"JupyterFlow Documentation"},{"location":"#what-is-jupyterflow","text":"Run Argo Workflow pipeline on JupyterHub. No Kubernetes knowledge (YAML) needed to run. No container build & push or deploy. Just simply run your workflow with single command jupyterflow . jupyterflow is a command that helps user utilize Argo Workflow engine without making any YAML files or building containers on JupyterHub. The following jupyterflow command will make sequence workflow. jupyterflow run -c \"python hello.py >> python world.py\"","title":"What is JupyterFlow?"},{"location":"#getting-started","text":"To set up jupyterflow and start running your first workflow, follow the Getting Started guide.","title":"Getting Started"},{"location":"#how-does-it-work","text":"To learn how it works, see How it works guide.","title":"How does it work"},{"location":"#examples","text":"For examples how to use, please see Examples page.","title":"Examples"},{"location":"#workflowyaml-configuration","text":"To find out more detail configuration, look at Configuration page.","title":"workflow.yaml Configuration"},{"location":"configuration/","text":"Configuring workflow file \u00b6 # workflow.yaml version : 1 name : workflow-name jobs : - python job1.py - python job2.py ARGS dags : - 1 >> 2 schedule : '*/2 * * * *' Property Description Optional Default version Version of workflow.yaml file format. Optional 1 name Name of the workflow. This name will used for Argo Workflow object name. Optional {username} of JupyterHub jobs Jobs to run. Any kinds of command will work. (Not just Python) Required dags Job dependencies. Index starts at 1. ( $PREVIOUS_JOB >> $NEXT_JOB ) Optional All jobs parallel (No dependency) schedule When to execute this workflow. Follows cron format. Optional Run immediately","title":"Configuring workflow file"},{"location":"configuration/#configuring-workflow-file","text":"# workflow.yaml version : 1 name : workflow-name jobs : - python job1.py - python job2.py ARGS dags : - 1 >> 2 schedule : '*/2 * * * *' Property Description Optional Default version Version of workflow.yaml file format. Optional 1 name Name of the workflow. This name will used for Argo Workflow object name. Optional {username} of JupyterHub jobs Jobs to run. Any kinds of command will work. (Not just Python) Required dags Job dependencies. Index starts at 1. ( $PREVIOUS_JOB >> $NEXT_JOB ) Optional All jobs parallel (No dependency) schedule When to execute this workflow. Follows cron format. Optional Run immediately","title":"Configuring workflow file"},{"location":"get-started/","text":"Get Started \u00b6 Although using jupyterflow does not require Kubernetes knowledge, Setting up jupyterflow requires Kubernetes knowledge(YAML, helm , Service ). If you're familiar with Kubernetes, it will not be too hard. This project only works on JupyterHub for Kubernetes. 1. Install Kubernetes \u00b6 Any Kubernetes distributions will work. Zero to JupyterHub has a wonderful guide for setting up Kubernetes. 2. Install JupyterHub \u00b6 Also, follow the Zero to JupyterHub instruction to set up JupyterHub. There is one thing you should be aware of while installing jupyterflow. Specify serviceAccoutName \u00b6 You need to specify serviceAccoutName in config.yaml . This service account will be used to create Argo Workflow object on behalf of you. For example, use default service account. Later, you should grant this service account to create Workflow object. # config.yaml singleuser : serviceAccountName : default 3. Install Argo Workflow \u00b6 Install Argo workflow with this page You need to install Argo workflow in the same Kubernetes namespace where JupyterHub is installed. For example, using jupyterflow namespace for JupyterHub and Argo Workflow. # create namespace jupyterflow kubectl create ns jupyterflow # install jupyterhub in jupyterflow helm install jupyterhub jupyterhub/jupyterhub --namespace jupyterflow # install argo workflow in jupyterflow kubectl apply --namespace jupyterflow -f \\ https://raw.githubusercontent.com/argoproj/argo/stable/manifests/quick-start-postgres.yaml 4. Expose Argo Workflow UI \u00b6 Expose Web UI for Argo Workflow: https://argoproj.github.io/argo/argo-server/ You need to expose Argo Web UI to see the result of jupyterflow . 5. Grant JupyterHub ServiceAccount RBAC \u00b6 Grant service account used in JupyterHub the ability to create Argo Workflow objects. Options 1) \u00b6 The simplest way to grant service account is to bind cluster-admin role. For example, if you deployed JupyterHub in jupyterflow namespace and specify service account as default # --serviceaccount=<NAMESPACE>:<SERVICE_ACCOUNT> kubectl create clusterrolebinding jupyterflow-admin \\ --clusterrole = cluster-admin \\ --serviceaccount = jupyterflow:default Options 2) \u00b6 For more fine-grained RBAC, create Workflow Role in the namespace where JupyterHub is installed. cat << EOF | kubectl create -n jupyterflow -f - apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: workflow-role rules: # pod get/watch is used to identify the container IDs of the current pod # pod patch is used to annotate the step's outputs back to controller (e.g. artifact location) - apiGroups: - \"\" resources: - pods verbs: - get - watch - patch # logs get/watch are used to get the pods logs for script outputs, and for log archival - apiGroups: - \"\" resources: - pods/log verbs: - get - watch EOF Then, bind Role with your service account. For example, binding default service account in jupyterflow namespace. kubectl create rolebinding workflow-rb \\ --role = workflow-role \\ --serviceaccount = jupyterflow:default \\ -n jupyterflow You might want to look at https://argoproj.github.io/argo/service-accounts 6. Install jupyterflow \u00b6 Finally, launch a JupyterHub notebook server and install jupyterflow using pip. pip install jupyterflow 7. Run Workflow \u00b6 Refer to examples/get-started Run by command \u00b6 Write your own code in notebook server. # job1.py print ( 'hello' ) # job2.py import sys print ( 'world %s !' % sys . argv [ 1 ]) Run following command for sequence workflow. jupyterflow run -c \"python job1.py >> python job2.py foo\" Go to Argo Web UI and check out the output of launched workflow. Run by workflow.yaml \u00b6 If you want to run more sophisticated workflow, such as DAG (Directed Acyclic Graph), write your workflow on file (for example, workflow.yaml , the name doen't matter) # workflow.yaml jobs : - python job1.py - python job2.py foo - python job2.py bar - python job3.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 2 >> 4 - 3 >> 4 # job3.py print ( 'again!' ) Run jupyteflow with -f option jupyterflow run -f workflow.yaml Check out the result.","title":"Get Started"},{"location":"get-started/#get-started","text":"Although using jupyterflow does not require Kubernetes knowledge, Setting up jupyterflow requires Kubernetes knowledge(YAML, helm , Service ). If you're familiar with Kubernetes, it will not be too hard. This project only works on JupyterHub for Kubernetes.","title":"Get Started"},{"location":"get-started/#1-install-kubernetes","text":"Any Kubernetes distributions will work. Zero to JupyterHub has a wonderful guide for setting up Kubernetes.","title":"1. Install Kubernetes"},{"location":"get-started/#2-install-jupyterhub","text":"Also, follow the Zero to JupyterHub instruction to set up JupyterHub. There is one thing you should be aware of while installing jupyterflow.","title":"2. Install JupyterHub"},{"location":"get-started/#specify-serviceaccoutname","text":"You need to specify serviceAccoutName in config.yaml . This service account will be used to create Argo Workflow object on behalf of you. For example, use default service account. Later, you should grant this service account to create Workflow object. # config.yaml singleuser : serviceAccountName : default","title":"Specify serviceAccoutName"},{"location":"get-started/#3-install-argo-workflow","text":"Install Argo workflow with this page You need to install Argo workflow in the same Kubernetes namespace where JupyterHub is installed. For example, using jupyterflow namespace for JupyterHub and Argo Workflow. # create namespace jupyterflow kubectl create ns jupyterflow # install jupyterhub in jupyterflow helm install jupyterhub jupyterhub/jupyterhub --namespace jupyterflow # install argo workflow in jupyterflow kubectl apply --namespace jupyterflow -f \\ https://raw.githubusercontent.com/argoproj/argo/stable/manifests/quick-start-postgres.yaml","title":"3. Install Argo Workflow"},{"location":"get-started/#4-expose-argo-workflow-ui","text":"Expose Web UI for Argo Workflow: https://argoproj.github.io/argo/argo-server/ You need to expose Argo Web UI to see the result of jupyterflow .","title":"4. Expose Argo Workflow UI"},{"location":"get-started/#5-grant-jupyterhub-serviceaccount-rbac","text":"Grant service account used in JupyterHub the ability to create Argo Workflow objects.","title":"5. Grant JupyterHub ServiceAccount RBAC"},{"location":"get-started/#options-1","text":"The simplest way to grant service account is to bind cluster-admin role. For example, if you deployed JupyterHub in jupyterflow namespace and specify service account as default # --serviceaccount=<NAMESPACE>:<SERVICE_ACCOUNT> kubectl create clusterrolebinding jupyterflow-admin \\ --clusterrole = cluster-admin \\ --serviceaccount = jupyterflow:default","title":"Options 1)"},{"location":"get-started/#options-2","text":"For more fine-grained RBAC, create Workflow Role in the namespace where JupyterHub is installed. cat << EOF | kubectl create -n jupyterflow -f - apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: workflow-role rules: # pod get/watch is used to identify the container IDs of the current pod # pod patch is used to annotate the step's outputs back to controller (e.g. artifact location) - apiGroups: - \"\" resources: - pods verbs: - get - watch - patch # logs get/watch are used to get the pods logs for script outputs, and for log archival - apiGroups: - \"\" resources: - pods/log verbs: - get - watch EOF Then, bind Role with your service account. For example, binding default service account in jupyterflow namespace. kubectl create rolebinding workflow-rb \\ --role = workflow-role \\ --serviceaccount = jupyterflow:default \\ -n jupyterflow You might want to look at https://argoproj.github.io/argo/service-accounts","title":"Options 2)"},{"location":"get-started/#6-install-jupyterflow","text":"Finally, launch a JupyterHub notebook server and install jupyterflow using pip. pip install jupyterflow","title":"6. Install jupyterflow"},{"location":"get-started/#7-run-workflow","text":"Refer to examples/get-started","title":"7. Run Workflow"},{"location":"get-started/#run-by-command","text":"Write your own code in notebook server. # job1.py print ( 'hello' ) # job2.py import sys print ( 'world %s !' % sys . argv [ 1 ]) Run following command for sequence workflow. jupyterflow run -c \"python job1.py >> python job2.py foo\" Go to Argo Web UI and check out the output of launched workflow.","title":"Run by command"},{"location":"get-started/#run-by-workflowyaml","text":"If you want to run more sophisticated workflow, such as DAG (Directed Acyclic Graph), write your workflow on file (for example, workflow.yaml , the name doen't matter) # workflow.yaml jobs : - python job1.py - python job2.py foo - python job2.py bar - python job3.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 2 >> 4 - 3 >> 4 # job3.py print ( 'again!' ) Run jupyteflow with -f option jupyterflow run -f workflow.yaml Check out the result.","title":"Run by workflow.yaml"},{"location":"how-it-works/","text":"How it works \u00b6 jupyterflow simply reads jupyter server Pod object to get all kinds of metadata, and reconstruct to Workflow object. jupyterflow uses following metadata from Pod . - Container image - Environment variables - Home directory (home PersistentVolumeClaim ) - Extra volume mount points - Resource management ( requests , limits ) - UID, GUID","title":"How it works"},{"location":"how-it-works/#how-it-works","text":"jupyterflow simply reads jupyter server Pod object to get all kinds of metadata, and reconstruct to Workflow object. jupyterflow uses following metadata from Pod . - Container image - Environment variables - Home directory (home PersistentVolumeClaim ) - Extra volume mount points - Resource management ( requests , limits ) - UID, GUID","title":"How it works"},{"location":"examples/","text":"Examples \u00b6","title":"Examples"},{"location":"examples/#examples","text":"","title":"Examples"},{"location":"examples/basic/","text":"Basic \u00b6","title":"Basic"},{"location":"examples/basic/#basic","text":"","title":"Basic"},{"location":"examples/ml-pipeline/","text":"ML Pipeline \u00b6 git clone https://github.com/hongkunyoo/jupyterflow.git cd examples/ml-pipeline ls -alh # input.py # train.py # output.py # workflow.yaml # requirements.txt input.py : train.py : output.py : workflow.yaml : requirements.txt : pip install -r requirements.txt python input.py python train.py softmax 0 .5 python output.py # workflow.yaml jobs : - python intput.py - python train.py softmax 0.5 - python train.py softmax 0.9 - python train.py relu 0.5 - python train.py relu 0.9 - python output.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 1 >> 4 - 1 >> 5 - 2 >> 6 - 3 >> 6 - 4 >> 6 - 5 >> 6 jupyterflow run -f workflow.yaml","title":"ML Pipeline"},{"location":"examples/ml-pipeline/#ml-pipeline","text":"git clone https://github.com/hongkunyoo/jupyterflow.git cd examples/ml-pipeline ls -alh # input.py # train.py # output.py # workflow.yaml # requirements.txt input.py : train.py : output.py : workflow.yaml : requirements.txt : pip install -r requirements.txt python input.py python train.py softmax 0 .5 python output.py # workflow.yaml jobs : - python intput.py - python train.py softmax 0.5 - python train.py softmax 0.9 - python train.py relu 0.5 - python train.py relu 0.9 - python output.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 1 >> 4 - 1 >> 5 - 2 >> 6 - 3 >> 6 - 4 >> 6 - 5 >> 6 jupyterflow run -f workflow.yaml","title":"ML Pipeline"}]}