{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"JupyterFlow \u00b6 Run your workflow on JupyterHub! What is JupyterFlow? \u00b6 Run your ML job right away on Kubernetes with jupyterflow . No container image build & push No Kubernetes manifest (YAML) Just simply run your ML code with single command jupyterflow . jupyterflow is a ML tool for Data Scientist to help run ML code on Kubernetes without any containerization process . Launch your jupyter notebook Write your ML code Run your ML model on Kubernetes through jupyterflow # Write your code. echo \"print('hello')\" > hello.py echo \"print('world')\" > world.py # Install jupyterflow. pip install jupyterflow # in jupyterflow `>>` directive expresses container dependencies similar to Airflow. jupyterflow run -c \"python hello.py >> python world.py\" Motivation \u00b6 I wanted to run ML models across multiple training server efficiently. Using Kubernetes was a good idea, since it is easy to run jobs distributedly. it is easy to schedule jobs on multiple training server. it has native resource management mechanism. it has good monitoring system. But there were some drawbacks. I needed to re-build & re-push image everytime I updated my model. This was painful. People who were not familiar with k8s had a hard time writing K8s manifest file. JupyterFlow aims to solve this problem. Run your workflow on JupyterHub with single command without containerization & k8s troublesome task. For more details, read this article. Limitation \u00b6 JupyterFlow only works on following platforms: JupyterHub for Kubernetes Kubeflow Therefore, although using JupyterFlow does not require Kubernetes manifest, setting up JupyterFlow requires Kubernetes understandings(YAML, helm , Service ). If you're familiar with Kubernetes, it will not be too hard. If you want to know why there is such limitation, refer to How it works guide. Getting Started \u00b6 To set up jupyterflow and start running your first workflow, follow the Getting Started guide. How it works \u00b6 To learn how it works, go to How it works guide. Examples \u00b6 For examples how to use, please see Examples page. Configuration \u00b6 To find out more configuration, take a look at Configuration page. CLI Reference \u00b6 For more detail usage of jupyterflow command line interface, find out more at CLI Reference page.","title":"Overview"},{"location":"#jupyterflow","text":"Run your workflow on JupyterHub!","title":"JupyterFlow"},{"location":"#what-is-jupyterflow","text":"Run your ML job right away on Kubernetes with jupyterflow . No container image build & push No Kubernetes manifest (YAML) Just simply run your ML code with single command jupyterflow . jupyterflow is a ML tool for Data Scientist to help run ML code on Kubernetes without any containerization process . Launch your jupyter notebook Write your ML code Run your ML model on Kubernetes through jupyterflow # Write your code. echo \"print('hello')\" > hello.py echo \"print('world')\" > world.py # Install jupyterflow. pip install jupyterflow # in jupyterflow `>>` directive expresses container dependencies similar to Airflow. jupyterflow run -c \"python hello.py >> python world.py\"","title":"What is JupyterFlow?"},{"location":"#motivation","text":"I wanted to run ML models across multiple training server efficiently. Using Kubernetes was a good idea, since it is easy to run jobs distributedly. it is easy to schedule jobs on multiple training server. it has native resource management mechanism. it has good monitoring system. But there were some drawbacks. I needed to re-build & re-push image everytime I updated my model. This was painful. People who were not familiar with k8s had a hard time writing K8s manifest file. JupyterFlow aims to solve this problem. Run your workflow on JupyterHub with single command without containerization & k8s troublesome task. For more details, read this article.","title":"Motivation"},{"location":"#limitation","text":"JupyterFlow only works on following platforms: JupyterHub for Kubernetes Kubeflow Therefore, although using JupyterFlow does not require Kubernetes manifest, setting up JupyterFlow requires Kubernetes understandings(YAML, helm , Service ). If you're familiar with Kubernetes, it will not be too hard. If you want to know why there is such limitation, refer to How it works guide.","title":"Limitation"},{"location":"#getting-started","text":"To set up jupyterflow and start running your first workflow, follow the Getting Started guide.","title":"Getting Started"},{"location":"#how-it-works","text":"To learn how it works, go to How it works guide.","title":"How it works"},{"location":"#examples","text":"For examples how to use, please see Examples page.","title":"Examples"},{"location":"#configuration","text":"To find out more configuration, take a look at Configuration page.","title":"Configuration"},{"location":"#cli-reference","text":"For more detail usage of jupyterflow command line interface, find out more at CLI Reference page.","title":"CLI Reference"},{"location":"cli-ref/","text":"CLI Reference \u00b6 jupyterflow is the command line interface for JupyterFlow jupyterflow run \u00b6 To run a workflow to Argo Workflow on JupyterHub Synopsis \u00b6 jupyterflow run [ flags ] Options \u00b6 -h, --help help for list -c, --command string Command to run workflow. ex) `jupyterflow run -c \"python main.py >> python next.py\"` -f, --filename string Path for workflow.yaml file. ex) `jupyterflow run -f workflow.yaml` -o, --output string Output format. (default is `-o jsonpath=\"metadata.name\"`, other possible options are yaml, json, jsonpath.) --dry-run Only prints Argo Workflow object, without accually sending it. Example \u00b6 jupyterflow run -f workflow.yaml jupyterflow delete \u00b6 Delete the given name of Argo Workflow. Synopsis \u00b6 jupyterflow delete WORKFLOW_NAME Example \u00b6 jupyterflow delete myworkflow-3f9c8 jupyterflow config \u00b6 View or create JupyterFlow configuration file to override Argo Workflow object specification. For detail information, refer to JupyterFlow Configuration Synopsis \u00b6 jupyterflow config [ flags ] Options \u00b6 -h, --help help for list --generate-config Generates default `$HOME/.jupyterflow.yaml` configuration file. Example \u00b6 jupyterflow config --generate-config","title":"CLI Reference"},{"location":"cli-ref/#cli-reference","text":"jupyterflow is the command line interface for JupyterFlow","title":"CLI Reference"},{"location":"cli-ref/#jupyterflow-run","text":"To run a workflow to Argo Workflow on JupyterHub","title":"jupyterflow run"},{"location":"cli-ref/#synopsis","text":"jupyterflow run [ flags ]","title":"Synopsis"},{"location":"cli-ref/#options","text":"-h, --help help for list -c, --command string Command to run workflow. ex) `jupyterflow run -c \"python main.py >> python next.py\"` -f, --filename string Path for workflow.yaml file. ex) `jupyterflow run -f workflow.yaml` -o, --output string Output format. (default is `-o jsonpath=\"metadata.name\"`, other possible options are yaml, json, jsonpath.) --dry-run Only prints Argo Workflow object, without accually sending it.","title":"Options"},{"location":"cli-ref/#example","text":"jupyterflow run -f workflow.yaml","title":"Example"},{"location":"cli-ref/#jupyterflow-delete","text":"Delete the given name of Argo Workflow.","title":"jupyterflow delete"},{"location":"cli-ref/#synopsis_1","text":"jupyterflow delete WORKFLOW_NAME","title":"Synopsis"},{"location":"cli-ref/#example_1","text":"jupyterflow delete myworkflow-3f9c8","title":"Example"},{"location":"cli-ref/#jupyterflow-config","text":"View or create JupyterFlow configuration file to override Argo Workflow object specification. For detail information, refer to JupyterFlow Configuration","title":"jupyterflow config"},{"location":"cli-ref/#synopsis_2","text":"jupyterflow config [ flags ]","title":"Synopsis"},{"location":"cli-ref/#options_1","text":"-h, --help help for list --generate-config Generates default `$HOME/.jupyterflow.yaml` configuration file.","title":"Options"},{"location":"cli-ref/#example_2","text":"jupyterflow config --generate-config","title":"Example"},{"location":"configuration/","text":"Configuration \u00b6 workflow.yaml Configuration \u00b6 workflow.yaml is a description about how to run your jobs. You can asign a dependencies between jobs. The name and the path does not matter as long as you pass to run -f option argument. Minimum description \u00b6 Each job will run in parallel. # workflow.yaml jobs : - echo hello - echo world - echo again jupyterflow run -f workflow.yaml Full description \u00b6 Job dependencies will be resolved based on dags information. # workflow.yaml version : 1 name : workflow-name jobs : - echo hello - echo world - echo again cmd_mode : exec # shell dags : - 1 >> 2 - 1 >> 3 schedule : '*/2 * * * *' Property Description Optional Default version Version of workflow.yaml file format. Optional 1 name Name of the workflow. This name is used for Argo Workflow name. Optional HOSTNAME of notebook jobs Jobs to run. Any kinds of command works. Required cmd_mode Specify command form, whether exec or shell . Optional exec dags Defining job dependencies. Index starts at 1. ( $PREVIOUS_JOB >> $NEXT_JOB ) Optional All jobs parallel (No dependency) schedule When to execute this workflow. Follows cron format. Optional Run immediately Comparing cmd_mode \u00b6 exec vs shell In exec mode, your command will be executed as [\"echo\", \"hello\"] . In shell mode, your command will be executed as [\"/bin/sh\", \"-c\", \"echo hello\"] . In exec mode, the command is more straightforward since there is no shell process involved and it is being called directly. In shell mode, you can fully utilize the power of shell, such as shell script commands. ( >> , && and so on.) For more detail explanation, refer to Docker run form Jupyterflow Configuration (Advanced) \u00b6 For more detail control of JupyterFlow, you can override Argo Workflow spec by configuring JupyterFlow config file(default: $HOME/.jupyterflow.yaml ). Configuring JupyterFlow requires Kubernetes Pod specification understandings. The following command will create .jupyterflow.yaml on $HOME directory. JupyterFlow configuration file path can be changed by setting JUPYTERFLOW_CONFIG_FILE environment variable( export JUPYTERFLOW_CONFIG_FILE=/tmp/myjupyterflow.yaml ). jupyterflow config --generate-config # jupyterflow config file created. cat $HOME /.jupyterflow.yaml # or run, `jupyterflow config` to view config # spec: # image: jupyter/datascience-notebook:latest # imagePullPolicy: Always # imagePullSecrets: # - name: \"default\" # env: # - name: \"CUSTOM_KEY\" # value: \"CUSTOM_VAL\" # resources: # requests: # cpu: 500m # memory: 500Mi # limits: # cpu: 500m # memory: 500Mi # nodeSelector: {} # runAsUser: 1000 # runAsGroup: 100 # serviceAccountName: default # volumes: # - name: nas001 # persistentVolumeClaim: # claimName: nas001 # volumeMounts: # - name: nas001 # mountPath: /nas001 Umcomment the property you want to override. For example, if you want your workflow jobs to run on GPU nodes, configure spec.resources or spec.nodeSelector property. spec: # image: jupyter/datascience-notebook:latest # imagePullPolicy: Always # imagePullSecrets: # - name: \"default\" # env: # - name: \"CUSTOM_KEY\" # value: \"CUSTOM_VAL\" resources: requests: cpu: 500m memory: 500Mi nvidia.com/gpu: 1 limits: cpu: 500m memory: 500Mi nvidia.com/gpu: 1 nodeSelector: accelerator: nvidia-node # runAsUser: 1000 # runAsGroup: 100 # serviceAccountName: default # volumes: # - name: nas001 # persistentVolumeClaim: # claimName: nas001 # volumeMounts: # - name: nas001 # mountPath: /nas001 Run jupyterflow and check out the result whether your workflow has run on GPU nodes. jupyterflow run -f workflow.yaml Note env , volumes , volumeMounts property will be appended to the original Pod spec, others will override the original Pod spec.","title":"Configuration"},{"location":"configuration/#configuration","text":"","title":"Configuration"},{"location":"configuration/#workflowyaml-configuration","text":"workflow.yaml is a description about how to run your jobs. You can asign a dependencies between jobs. The name and the path does not matter as long as you pass to run -f option argument.","title":"workflow.yaml Configuration"},{"location":"configuration/#minimum-description","text":"Each job will run in parallel. # workflow.yaml jobs : - echo hello - echo world - echo again jupyterflow run -f workflow.yaml","title":"Minimum description"},{"location":"configuration/#full-description","text":"Job dependencies will be resolved based on dags information. # workflow.yaml version : 1 name : workflow-name jobs : - echo hello - echo world - echo again cmd_mode : exec # shell dags : - 1 >> 2 - 1 >> 3 schedule : '*/2 * * * *' Property Description Optional Default version Version of workflow.yaml file format. Optional 1 name Name of the workflow. This name is used for Argo Workflow name. Optional HOSTNAME of notebook jobs Jobs to run. Any kinds of command works. Required cmd_mode Specify command form, whether exec or shell . Optional exec dags Defining job dependencies. Index starts at 1. ( $PREVIOUS_JOB >> $NEXT_JOB ) Optional All jobs parallel (No dependency) schedule When to execute this workflow. Follows cron format. Optional Run immediately","title":"Full description"},{"location":"configuration/#comparing-cmd_mode","text":"exec vs shell In exec mode, your command will be executed as [\"echo\", \"hello\"] . In shell mode, your command will be executed as [\"/bin/sh\", \"-c\", \"echo hello\"] . In exec mode, the command is more straightforward since there is no shell process involved and it is being called directly. In shell mode, you can fully utilize the power of shell, such as shell script commands. ( >> , && and so on.) For more detail explanation, refer to Docker run form","title":"Comparing cmd_mode"},{"location":"configuration/#jupyterflow-configuration-advanced","text":"For more detail control of JupyterFlow, you can override Argo Workflow spec by configuring JupyterFlow config file(default: $HOME/.jupyterflow.yaml ). Configuring JupyterFlow requires Kubernetes Pod specification understandings. The following command will create .jupyterflow.yaml on $HOME directory. JupyterFlow configuration file path can be changed by setting JUPYTERFLOW_CONFIG_FILE environment variable( export JUPYTERFLOW_CONFIG_FILE=/tmp/myjupyterflow.yaml ). jupyterflow config --generate-config # jupyterflow config file created. cat $HOME /.jupyterflow.yaml # or run, `jupyterflow config` to view config # spec: # image: jupyter/datascience-notebook:latest # imagePullPolicy: Always # imagePullSecrets: # - name: \"default\" # env: # - name: \"CUSTOM_KEY\" # value: \"CUSTOM_VAL\" # resources: # requests: # cpu: 500m # memory: 500Mi # limits: # cpu: 500m # memory: 500Mi # nodeSelector: {} # runAsUser: 1000 # runAsGroup: 100 # serviceAccountName: default # volumes: # - name: nas001 # persistentVolumeClaim: # claimName: nas001 # volumeMounts: # - name: nas001 # mountPath: /nas001 Umcomment the property you want to override. For example, if you want your workflow jobs to run on GPU nodes, configure spec.resources or spec.nodeSelector property. spec: # image: jupyter/datascience-notebook:latest # imagePullPolicy: Always # imagePullSecrets: # - name: \"default\" # env: # - name: \"CUSTOM_KEY\" # value: \"CUSTOM_VAL\" resources: requests: cpu: 500m memory: 500Mi nvidia.com/gpu: 1 limits: cpu: 500m memory: 500Mi nvidia.com/gpu: 1 nodeSelector: accelerator: nvidia-node # runAsUser: 1000 # runAsGroup: 100 # serviceAccountName: default # volumes: # - name: nas001 # persistentVolumeClaim: # claimName: nas001 # volumeMounts: # - name: nas001 # mountPath: /nas001 Run jupyterflow and check out the result whether your workflow has run on GPU nodes. jupyterflow run -f workflow.yaml Note env , volumes , volumeMounts property will be appended to the original Pod spec, others will override the original Pod spec.","title":"Jupyterflow Configuration (Advanced)"},{"location":"get-started/","text":"Get Started \u00b6 Although using JupyterFlow does not require Kubernetes knowledge, setting up JupyterFlow requires Kubernetes understandings(YAML, helm , Service ). If you're familiar with Kubernetes, it will not be too hard. This project only works on JupyterHub for Kubernetes and Kubeflow. Options for setting up JupyterFlow \u00b6 There are two ways to set up jupyterflow Set up JupyterFlow on JupyterHub. Set up JupyterFlow on Kubeflow. After the setup, you can run your workflow with jupyterflow on Kubernetes. Launch your jupyter notebook and follow the example. Run my first workflow \u00b6 Refer to examples/get-started to get the example scripts. By command \u00b6 Write your own code in notebook server. # job1.py print ( 'hello' ) # job2.py import sys print ( 'world %s !' % sys . argv [ 1 ]) Run following command for sequence workflow. jupyterflow run -c \"python job1.py >> python job2.py foo\" Go to Argo Web UI and check out the output of launched workflow. By workflow.yaml file \u00b6 If you want to run more sophisticated workflow, such as DAG (Directed Acyclic Graph), write your own workflow file (for example, workflow.yaml , the name doesn't matter) For more information, check out Configuring workflow # job3.py print ( 'again!' ) # workflow.yaml jobs : - python job1.py - python job2.py foo - python job2.py bar - python job3.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 2 >> 4 - 3 >> 4 Run jupyteflow with -f option. jupyterflow run -f workflow.yaml Check out the result.","title":"Get Started"},{"location":"get-started/#get-started","text":"Although using JupyterFlow does not require Kubernetes knowledge, setting up JupyterFlow requires Kubernetes understandings(YAML, helm , Service ). If you're familiar with Kubernetes, it will not be too hard. This project only works on JupyterHub for Kubernetes and Kubeflow.","title":"Get Started"},{"location":"get-started/#options-for-setting-up-jupyterflow","text":"There are two ways to set up jupyterflow Set up JupyterFlow on JupyterHub. Set up JupyterFlow on Kubeflow. After the setup, you can run your workflow with jupyterflow on Kubernetes. Launch your jupyter notebook and follow the example.","title":"Options for setting up JupyterFlow"},{"location":"get-started/#run-my-first-workflow","text":"Refer to examples/get-started to get the example scripts.","title":"Run my first workflow"},{"location":"get-started/#by-command","text":"Write your own code in notebook server. # job1.py print ( 'hello' ) # job2.py import sys print ( 'world %s !' % sys . argv [ 1 ]) Run following command for sequence workflow. jupyterflow run -c \"python job1.py >> python job2.py foo\" Go to Argo Web UI and check out the output of launched workflow.","title":"By command"},{"location":"get-started/#by-workflowyaml-file","text":"If you want to run more sophisticated workflow, such as DAG (Directed Acyclic Graph), write your own workflow file (for example, workflow.yaml , the name doesn't matter) For more information, check out Configuring workflow # job3.py print ( 'again!' ) # workflow.yaml jobs : - python job1.py - python job2.py foo - python job2.py bar - python job3.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 2 >> 4 - 3 >> 4 Run jupyteflow with -f option. jupyterflow run -f workflow.yaml Check out the result.","title":"By workflow.yaml file"},{"location":"how-it-works/","text":"How it works \u00b6 JupyterFlow has a strict constraint that it only works on Kubernetes( JupyterHub for Kubernetes or Kubeflow ). This is because JupyterFlow collects user's execution environment information from Pod metadata and the source code from Kubernetes storage volume. JupyterFlow uses these information to construct a new Kubernetes manifest(Argo Workflow ) for ML job without any containerization on behalf of you. jupyterflow collects following metadata from jupyter notebook Pod . Container image Environment variables Home directory volume (home PersistentVolumeClaim ) Extra volume mount points Resource management ( requests , limits ) NodeSelector label UID, GUID Etc. Following pseudo code might help you understand how jupyterflow works. JupyterFlow main logic jupyterflow run - c \"python hello.py >> python world.py\" # ... # inside jupyterflow # ... # get user workflow(DAG) information. user_workflow_data = get_user_workflow ( user_input ) # collect metadata of current environment(jupyter notebook Pod). nb_pod_spec = get_current_pod_spec_from_k8s ( jupyter_notebook_pod_name , service_account ) # build Workflow manifest based on meta data and user workflow information. argo_workflow_spec = build_workflow ( nb_pod_spec , user_workflow_data ) # request new Argo workflow. response = request_for_new_workflow_to_k8s ( K8S_MASTER , argo_workflow_spec , service_account ) For more details, please read this article.","title":"How it works"},{"location":"how-it-works/#how-it-works","text":"JupyterFlow has a strict constraint that it only works on Kubernetes( JupyterHub for Kubernetes or Kubeflow ). This is because JupyterFlow collects user's execution environment information from Pod metadata and the source code from Kubernetes storage volume. JupyterFlow uses these information to construct a new Kubernetes manifest(Argo Workflow ) for ML job without any containerization on behalf of you. jupyterflow collects following metadata from jupyter notebook Pod . Container image Environment variables Home directory volume (home PersistentVolumeClaim ) Extra volume mount points Resource management ( requests , limits ) NodeSelector label UID, GUID Etc. Following pseudo code might help you understand how jupyterflow works. JupyterFlow main logic jupyterflow run - c \"python hello.py >> python world.py\" # ... # inside jupyterflow # ... # get user workflow(DAG) information. user_workflow_data = get_user_workflow ( user_input ) # collect metadata of current environment(jupyter notebook Pod). nb_pod_spec = get_current_pod_spec_from_k8s ( jupyter_notebook_pod_name , service_account ) # build Workflow manifest based on meta data and user workflow information. argo_workflow_spec = build_workflow ( nb_pod_spec , user_workflow_data ) # request new Argo workflow. response = request_for_new_workflow_to_k8s ( K8S_MASTER , argo_workflow_spec , service_account ) For more details, please read this article.","title":"How it works"},{"location":"jupyterhub/","text":"Set up on JupyterHub \u00b6 In this method, you will install JupyterHub, Argo Workflow manually. Prerequisite \u00b6 Create Kubernetes cluster. Install kubectl command. Install helm command. Any Kubernetes cluster will work. Zero to JupyterHub has a wonderful guide for setting up Kubernetes. Install JupyterHub \u00b6 Follow the Zero to JupyterHub instruction to set up JupyterHub . There are two things you should configure to use jupyterflow . 1) Specify serviceAccoutName \u00b6 Specify singleuser.serviceAccoutName property in config.yaml . This service account will be used to create Argo Workflow object on behalf of you. For example, following configuration uses default service account. Later, you should grant this service account a proper role to create Workflow object. # config.yaml singleuser : serviceAccountName : default 2) Configure Storage \u00b6 You need a shared storage volume, such as NFS server( ReadWriteMany access mode), to make JupyterFlow get the same ML code written in Jupyter notebook. To do this, configure singleuser.storage property. If you're unfamiliar with storage access mode, take a look at Kubernetes persistent volume access mode . The simplest way to have a ReadWriteMany type storage is installing nfs-server-provisioner. # StorageClass name will be nfs-server helm install nfs-server stable/nfs-server-provisioner And then use the nfs-server StorageClass for ReadWriteMany access mode storage in config.yaml file. # config.yaml singleuser : storage : type : dynamic # dynamic or static dynamic : storageClass : nfs-server # For example, nfs-server-provisioner storageAccessModes : [ ReadWriteMany ] # Make sure your volume supports ReadWriteMany. static : # Static pvc also works fine. pvcName : my-static-pvc # Static pvc should support ReadWriteMany mode. The full description of config.yaml file will seem like this. # config.yaml proxy : secretToken : \"<RANDOM_HEX>\" # openssl rand -hex 32 singleuser : serviceAccountName : default storage : type : dynamic dynamic : storageClass : nfs-server storageAccessModes : [ ReadWriteMany ] Install JupyterHub using helm package manager. Following example installs JupyterHub in jupyterflow namespace. helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/ helm repo update RELEASE = jhub NAMESPACE = jupyterflow helm install $RELEASE jupyterhub/jupyterhub \\ --namespace $NAMESPACE \\ --create-namespace \\ --values config.yaml Install Argo Workflow Engine \u00b6 Install Argo workflow engine with Argo Workflow quick start page . You need to install Argo workflow engine in the same Kubernetes namespace where JupyterHub is installed. For example, use jupyterflow namespace for installing Argo Workflow engine. kubectl apply --namespace jupyterflow -f \\ https://raw.githubusercontent.com/argoproj/argo/stable/manifests/quick-start-postgres.yaml Note If you want to install Argo workflow engine in different namespace, refer to Argo installation - cluster install page. Expose Argo Workflow Web UI \u00b6 You need to expose Argo web UI to see the result of jupyterflow . The simplest way is to expose argo-server Service as LoadBalancer type. For example, if your Argo workflow engine is deployed in jupyterflow namespace, run # Expose argo-server Service as LoadBalancer type kubectl patch svc argo-server -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' -n jupyterflow # service/argo-server patched Browse <LOAD_BALANCER_IP>:2746 to see Argo Workflow web UI is available. For detail configuration, refer to https://argoproj.github.io/argo-workflows/argo-server/ Grant JupyterHub Service Account RBAC \u00b6 Grant the service account used in JupyterHub a role to create Argo Workflow objects. Options 1) \u00b6 The simplest way to grant service account is to bind cluster-admin role. For example, if you deployed JupyterHub in jupyterflow namespace and specify service account as default , run # binding cluster-admin role to jupyterflow:default kubectl create clusterrolebinding jupyterflow-admin \\ --clusterrole = cluster-admin \\ --serviceaccount = jupyterflow:default Options 2) \u00b6 For more fine-grained Access Control, create Workflow Role in the namespace where JupyterHub is installed. For example, create Workflow Role in jupyterflow namespace with following command. cat << EOF | kubectl apply -n jupyterflow -f - apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: workflow-role rules: # pod get/watch is used to identify the container IDs of the current pod # pod patch is used to annotate the step's outputs back to controller (e.g. artifact location) - apiGroups: - \"\" resources: - pods verbs: - get - watch - patch - list # logs get/watch are used to get the pods logs for script outputs, and for log archival - apiGroups: - \"\" resources: - pods/log verbs: - get - watch - apiGroups: - \"argoproj.io\" resources: - workflows verbs: - get - watch - patch - list - create EOF Then, bind the Role with your service account. For example, bind default service account with workflow role in jupyterflow namespace. # binding workflow role to jupyterflow:default kubectl create rolebinding workflow-rb \\ --role = workflow-role \\ --serviceaccount = jupyterflow:default \\ --namespace jupyterflow You might want to look at https://argoproj.github.io/argo-workflows/service-accounts for granting permissions. Install jupyterflow \u00b6 Finally, launch a JupyterHub notebook server and install jupyterflow using pip. In jupyter notebook Terminal, run pip install jupyterflow","title":"Set up on JupyterHub"},{"location":"jupyterhub/#set-up-on-jupyterhub","text":"In this method, you will install JupyterHub, Argo Workflow manually.","title":"Set up on JupyterHub"},{"location":"jupyterhub/#prerequisite","text":"Create Kubernetes cluster. Install kubectl command. Install helm command. Any Kubernetes cluster will work. Zero to JupyterHub has a wonderful guide for setting up Kubernetes.","title":"Prerequisite"},{"location":"jupyterhub/#install-jupyterhub","text":"Follow the Zero to JupyterHub instruction to set up JupyterHub . There are two things you should configure to use jupyterflow .","title":"Install JupyterHub"},{"location":"jupyterhub/#1-specify-serviceaccoutname","text":"Specify singleuser.serviceAccoutName property in config.yaml . This service account will be used to create Argo Workflow object on behalf of you. For example, following configuration uses default service account. Later, you should grant this service account a proper role to create Workflow object. # config.yaml singleuser : serviceAccountName : default","title":"1) Specify serviceAccoutName"},{"location":"jupyterhub/#2-configure-storage","text":"You need a shared storage volume, such as NFS server( ReadWriteMany access mode), to make JupyterFlow get the same ML code written in Jupyter notebook. To do this, configure singleuser.storage property. If you're unfamiliar with storage access mode, take a look at Kubernetes persistent volume access mode . The simplest way to have a ReadWriteMany type storage is installing nfs-server-provisioner. # StorageClass name will be nfs-server helm install nfs-server stable/nfs-server-provisioner And then use the nfs-server StorageClass for ReadWriteMany access mode storage in config.yaml file. # config.yaml singleuser : storage : type : dynamic # dynamic or static dynamic : storageClass : nfs-server # For example, nfs-server-provisioner storageAccessModes : [ ReadWriteMany ] # Make sure your volume supports ReadWriteMany. static : # Static pvc also works fine. pvcName : my-static-pvc # Static pvc should support ReadWriteMany mode. The full description of config.yaml file will seem like this. # config.yaml proxy : secretToken : \"<RANDOM_HEX>\" # openssl rand -hex 32 singleuser : serviceAccountName : default storage : type : dynamic dynamic : storageClass : nfs-server storageAccessModes : [ ReadWriteMany ] Install JupyterHub using helm package manager. Following example installs JupyterHub in jupyterflow namespace. helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/ helm repo update RELEASE = jhub NAMESPACE = jupyterflow helm install $RELEASE jupyterhub/jupyterhub \\ --namespace $NAMESPACE \\ --create-namespace \\ --values config.yaml","title":"2) Configure Storage"},{"location":"jupyterhub/#install-argo-workflow-engine","text":"Install Argo workflow engine with Argo Workflow quick start page . You need to install Argo workflow engine in the same Kubernetes namespace where JupyterHub is installed. For example, use jupyterflow namespace for installing Argo Workflow engine. kubectl apply --namespace jupyterflow -f \\ https://raw.githubusercontent.com/argoproj/argo/stable/manifests/quick-start-postgres.yaml Note If you want to install Argo workflow engine in different namespace, refer to Argo installation - cluster install page.","title":"Install Argo Workflow Engine"},{"location":"jupyterhub/#expose-argo-workflow-web-ui","text":"You need to expose Argo web UI to see the result of jupyterflow . The simplest way is to expose argo-server Service as LoadBalancer type. For example, if your Argo workflow engine is deployed in jupyterflow namespace, run # Expose argo-server Service as LoadBalancer type kubectl patch svc argo-server -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' -n jupyterflow # service/argo-server patched Browse <LOAD_BALANCER_IP>:2746 to see Argo Workflow web UI is available. For detail configuration, refer to https://argoproj.github.io/argo-workflows/argo-server/","title":"Expose Argo Workflow Web UI"},{"location":"jupyterhub/#grant-jupyterhub-service-account-rbac","text":"Grant the service account used in JupyterHub a role to create Argo Workflow objects.","title":"Grant JupyterHub Service Account RBAC"},{"location":"jupyterhub/#options-1","text":"The simplest way to grant service account is to bind cluster-admin role. For example, if you deployed JupyterHub in jupyterflow namespace and specify service account as default , run # binding cluster-admin role to jupyterflow:default kubectl create clusterrolebinding jupyterflow-admin \\ --clusterrole = cluster-admin \\ --serviceaccount = jupyterflow:default","title":"Options 1)"},{"location":"jupyterhub/#options-2","text":"For more fine-grained Access Control, create Workflow Role in the namespace where JupyterHub is installed. For example, create Workflow Role in jupyterflow namespace with following command. cat << EOF | kubectl apply -n jupyterflow -f - apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: workflow-role rules: # pod get/watch is used to identify the container IDs of the current pod # pod patch is used to annotate the step's outputs back to controller (e.g. artifact location) - apiGroups: - \"\" resources: - pods verbs: - get - watch - patch - list # logs get/watch are used to get the pods logs for script outputs, and for log archival - apiGroups: - \"\" resources: - pods/log verbs: - get - watch - apiGroups: - \"argoproj.io\" resources: - workflows verbs: - get - watch - patch - list - create EOF Then, bind the Role with your service account. For example, bind default service account with workflow role in jupyterflow namespace. # binding workflow role to jupyterflow:default kubectl create rolebinding workflow-rb \\ --role = workflow-role \\ --serviceaccount = jupyterflow:default \\ --namespace jupyterflow You might want to look at https://argoproj.github.io/argo-workflows/service-accounts for granting permissions.","title":"Options 2)"},{"location":"jupyterhub/#install-jupyterflow","text":"Finally, launch a JupyterHub notebook server and install jupyterflow using pip. In jupyter notebook Terminal, run pip install jupyterflow","title":"Install jupyterflow"},{"location":"kubeflow/","text":"Set up on Kubeflow \u00b6 What is Kubeflow? \u00b6 Kubeflow is a free and open-source machine learning platform designed to enable using machine learning pipelines to orchestrate complicated workflows running on Kubernetes. In this method, you will install JupyterFlow on existing Kubeflow platform. Install Kubeflow \u00b6 Refer to kubeflow getting started page for installation. Configure Storage \u00b6 You need a shared storage volume, such as NFS server( ReadWriteMany access mode), to make JupyterFlow get the same ML code written in Jupyter notebook. To do this, configure singleuser.storage property. If you're unfamiliar with storage access mode, take a look at Kubernetes persistent volume access mode . The simplest way to have a ReadWriteMany type storage is installing nfs-server-provisioner. # StorageClass name will be nfs-server helm install nfs-server stable/nfs-server-provisioner Select ReadWriteMany access mode storage when launching your notebook server on Kubeflow Notebook Server. Expose Argo Workflow Web UI \u00b6 You need to expose Argo web UI to see the result of jupyterflow . Unfortunately, JupyterFlow currently does not support Kubeflow Pipelines, so the result of juypterflow workflow does not appear in Kubeflow Pipelines web pages. You need to manually expose Argo Workflow web UI to check out the result. The simplest way to expose Argo Workflow web UI is changing argo-ui Service to LoadBalancer type. # Expose argo-ui Service as LoadBalancer type kubectl patch svc argo-ui -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' -n kubeflow # service/argo-ui patched And then change Argo UI deployment environment variable. To find out the reason, take a look at Argo issue#1215 # Change BASE_HREF env to / kubectl set env deployment/argo-ui BASE_HREF = / -n kubeflow # deployment.apps/argo-ui env updated Browse <LOAD_BALANCER_IP>:80 to see Argo Workflow web UI is available. For detail configuration, refer to https://argoproj.github.io/argo-workflows/argo-server/ Grant Kubeflow notebook Service Account RBAC \u00b6 Grant the service account used in Kubeflow notebook a role to create Argo Workflow objects. The default service account name in Kubeflow notebook is default-editor . Options 1) \u00b6 The simplest way to grant service account is to bind cluster-admin role. Assuming your Kubeflow namespace is jupyterflow , run # binding cluster-admin role to jupyterflow:default-editor kubectl create clusterrolebinding jupyterflow-admin \\ --clusterrole = cluster-admin \\ --serviceaccount = jupyterflow:default-editor Options 2) \u00b6 For more fine-grained Access Control, create Workflow Role in the namespace where Kubeflow is installed. For example, create Workflow Role in jupyterflow namespace with following command. cat << EOF | kubectl apply -n jupyterflow -f - apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: workflow-role rules: # pod get/watch is used to identify the container IDs of the current pod # pod patch is used to annotate the step's outputs back to controller (e.g. artifact location) - apiGroups: - \"\" resources: - pods verbs: - get - watch - patch - list # logs get/watch are used to get the pods logs for script outputs, and for log archival - apiGroups: - \"\" resources: - pods/log verbs: - get - watch - apiGroups: - \"argoproj.io\" resources: - workflows verbs: - get - watch - patch - list - create EOF Then, bind the Role with your service account. For example, bind default-editor service account with workflow role in jupyterflow namespace. # binding workflow role to jupyterflow:default-editor kubectl create rolebinding workflow-rb \\ --role = workflow-role \\ --serviceaccount = jupyterflow:default-editor \\ --namespace jupyterflow You might want to look at https://argoproj.github.io/argo-workflows/service-accounts for granting permissions. Install jupyterflow \u00b6 Finally, launch a JupyterHub notebook server and install jupyterflow using pip. In jupyter notebook Terminal, run pip install jupyterflow","title":"Set up on Kubeflow"},{"location":"kubeflow/#set-up-on-kubeflow","text":"","title":"Set up on Kubeflow"},{"location":"kubeflow/#what-is-kubeflow","text":"Kubeflow is a free and open-source machine learning platform designed to enable using machine learning pipelines to orchestrate complicated workflows running on Kubernetes. In this method, you will install JupyterFlow on existing Kubeflow platform.","title":"What is Kubeflow?"},{"location":"kubeflow/#install-kubeflow","text":"Refer to kubeflow getting started page for installation.","title":"Install Kubeflow"},{"location":"kubeflow/#configure-storage","text":"You need a shared storage volume, such as NFS server( ReadWriteMany access mode), to make JupyterFlow get the same ML code written in Jupyter notebook. To do this, configure singleuser.storage property. If you're unfamiliar with storage access mode, take a look at Kubernetes persistent volume access mode . The simplest way to have a ReadWriteMany type storage is installing nfs-server-provisioner. # StorageClass name will be nfs-server helm install nfs-server stable/nfs-server-provisioner Select ReadWriteMany access mode storage when launching your notebook server on Kubeflow Notebook Server.","title":"Configure Storage"},{"location":"kubeflow/#expose-argo-workflow-web-ui","text":"You need to expose Argo web UI to see the result of jupyterflow . Unfortunately, JupyterFlow currently does not support Kubeflow Pipelines, so the result of juypterflow workflow does not appear in Kubeflow Pipelines web pages. You need to manually expose Argo Workflow web UI to check out the result. The simplest way to expose Argo Workflow web UI is changing argo-ui Service to LoadBalancer type. # Expose argo-ui Service as LoadBalancer type kubectl patch svc argo-ui -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' -n kubeflow # service/argo-ui patched And then change Argo UI deployment environment variable. To find out the reason, take a look at Argo issue#1215 # Change BASE_HREF env to / kubectl set env deployment/argo-ui BASE_HREF = / -n kubeflow # deployment.apps/argo-ui env updated Browse <LOAD_BALANCER_IP>:80 to see Argo Workflow web UI is available. For detail configuration, refer to https://argoproj.github.io/argo-workflows/argo-server/","title":"Expose Argo Workflow Web UI"},{"location":"kubeflow/#grant-kubeflow-notebook-service-account-rbac","text":"Grant the service account used in Kubeflow notebook a role to create Argo Workflow objects. The default service account name in Kubeflow notebook is default-editor .","title":"Grant Kubeflow notebook Service Account RBAC"},{"location":"kubeflow/#options-1","text":"The simplest way to grant service account is to bind cluster-admin role. Assuming your Kubeflow namespace is jupyterflow , run # binding cluster-admin role to jupyterflow:default-editor kubectl create clusterrolebinding jupyterflow-admin \\ --clusterrole = cluster-admin \\ --serviceaccount = jupyterflow:default-editor","title":"Options 1)"},{"location":"kubeflow/#options-2","text":"For more fine-grained Access Control, create Workflow Role in the namespace where Kubeflow is installed. For example, create Workflow Role in jupyterflow namespace with following command. cat << EOF | kubectl apply -n jupyterflow -f - apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: workflow-role rules: # pod get/watch is used to identify the container IDs of the current pod # pod patch is used to annotate the step's outputs back to controller (e.g. artifact location) - apiGroups: - \"\" resources: - pods verbs: - get - watch - patch - list # logs get/watch are used to get the pods logs for script outputs, and for log archival - apiGroups: - \"\" resources: - pods/log verbs: - get - watch - apiGroups: - \"argoproj.io\" resources: - workflows verbs: - get - watch - patch - list - create EOF Then, bind the Role with your service account. For example, bind default-editor service account with workflow role in jupyterflow namespace. # binding workflow role to jupyterflow:default-editor kubectl create rolebinding workflow-rb \\ --role = workflow-role \\ --serviceaccount = jupyterflow:default-editor \\ --namespace jupyterflow You might want to look at https://argoproj.github.io/argo-workflows/service-accounts for granting permissions.","title":"Options 2)"},{"location":"kubeflow/#install-jupyterflow","text":"Finally, launch a JupyterHub notebook server and install jupyterflow using pip. In jupyter notebook Terminal, run pip install jupyterflow","title":"Install jupyterflow"},{"location":"examples/","text":"Examples \u00b6 Basic \u00b6 Basic example for beginners. It shows any type of command is possible to run only if it's install in your jupyter notebook. ML Pipeline \u00b6 ML pipeline example for machine learning experiments. You can run various ML train job easily with jupyterflow command. This is the one of the main reason why you should use jupyterflow .","title":"Examples"},{"location":"examples/#examples","text":"","title":"Examples"},{"location":"examples/#basic","text":"Basic example for beginners. It shows any type of command is possible to run only if it's install in your jupyter notebook.","title":"Basic"},{"location":"examples/#ml-pipeline","text":"ML pipeline example for machine learning experiments. You can run various ML train job easily with jupyterflow command. This is the one of the main reason why you should use jupyterflow .","title":"ML Pipeline"},{"location":"examples/basic/","text":"Basic \u00b6 Run by command \u00b6 Clone jupyterflow git repository and go to examples/basic . git clone https://github.com/hongkunyoo/jupyterflow.git cd examples/basic ls -alh # hello.sh # workflow.yaml hello.sh : Script to run in workflow. workflow.yaml : workflow file hello.sh script looks like this. it simply echos argument. # hello.sh echo \"Hello $1 \" Run jupyterflow with -c option for simple command. jupyterflow run -c \"bash hello.sh world >> echo 'good bye'\" Go to Argo Web UI and check out the output of launched workflow. Run by workflow.yaml \u00b6 Write workflow.yaml for parallel execution. # workflow.yaml jobs : - bash hello.sh world - bash hello.sh bob - bash hello.sh foo - ls - echo 'jupyterflow is the best!' # Job index starts at 1. dags : - 1 >> 4 - 2 >> 4 - 3 >> 4 - 4 >> 5 Run jupyteflow with -f option. jupyterflow run -f workflow.yaml Check out the result.","title":"Basic"},{"location":"examples/basic/#basic","text":"","title":"Basic"},{"location":"examples/basic/#run-by-command","text":"Clone jupyterflow git repository and go to examples/basic . git clone https://github.com/hongkunyoo/jupyterflow.git cd examples/basic ls -alh # hello.sh # workflow.yaml hello.sh : Script to run in workflow. workflow.yaml : workflow file hello.sh script looks like this. it simply echos argument. # hello.sh echo \"Hello $1 \" Run jupyterflow with -c option for simple command. jupyterflow run -c \"bash hello.sh world >> echo 'good bye'\" Go to Argo Web UI and check out the output of launched workflow.","title":"Run by command"},{"location":"examples/basic/#run-by-workflowyaml","text":"Write workflow.yaml for parallel execution. # workflow.yaml jobs : - bash hello.sh world - bash hello.sh bob - bash hello.sh foo - ls - echo 'jupyterflow is the best!' # Job index starts at 1. dags : - 1 >> 4 - 2 >> 4 - 3 >> 4 - 4 >> 5 Run jupyteflow with -f option. jupyterflow run -f workflow.yaml Check out the result.","title":"Run by workflow.yaml"},{"location":"examples/ml-pipeline/","text":"ML Pipeline \u00b6 Clone jupyterflow git repository and go to examples/ml-pipeline . git clone https://github.com/hongkunyoo/jupyterflow.git cd examples/ml-pipeline ls -alh # input.py # train.py # output.py # workflow.yaml # requirements.txt input.py : Script for preparing train data. train.py : Model training experiments. output.py : Scores trained models. workflow.yaml : jupyterflow workflow file requirements.txt : Pip packages for ML pipeline First, install required packages. pip install -r requirements.txt Run each script in jupyter notebook for testing purpose. python input.py python train.py softmax 0 .5 python output.py Write various training experiments to find the best performing model. # workflow.yaml jobs : - python input.py - python train.py softmax 0.5 - python train.py softmax 0.9 - python train.py relu 0.5 - python train.py relu 0.9 - python output.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 1 >> 4 - 1 >> 5 - 2 >> 6 - 3 >> 6 - 4 >> 6 - 5 >> 6 Run your ML Pipeline. jupyterflow run -f workflow.yaml Check out the result in Argo Web UI.","title":"ML Pipeline"},{"location":"examples/ml-pipeline/#ml-pipeline","text":"Clone jupyterflow git repository and go to examples/ml-pipeline . git clone https://github.com/hongkunyoo/jupyterflow.git cd examples/ml-pipeline ls -alh # input.py # train.py # output.py # workflow.yaml # requirements.txt input.py : Script for preparing train data. train.py : Model training experiments. output.py : Scores trained models. workflow.yaml : jupyterflow workflow file requirements.txt : Pip packages for ML pipeline First, install required packages. pip install -r requirements.txt Run each script in jupyter notebook for testing purpose. python input.py python train.py softmax 0 .5 python output.py Write various training experiments to find the best performing model. # workflow.yaml jobs : - python input.py - python train.py softmax 0.5 - python train.py softmax 0.9 - python train.py relu 0.5 - python train.py relu 0.9 - python output.py # Job index starts at 1. dags : - 1 >> 2 - 1 >> 3 - 1 >> 4 - 1 >> 5 - 2 >> 6 - 3 >> 6 - 4 >> 6 - 5 >> 6 Run your ML Pipeline. jupyterflow run -f workflow.yaml Check out the result in Argo Web UI.","title":"ML Pipeline"}]}